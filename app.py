import streamlit as st
import json
import pandas as pd
import base64
import requests
from streamlit.components.v1 import html
import streamlit.components.v1 as components

GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = st.secrets["REPO_OWNER"]
REPO_NAME = st.secrets["REPO_NAME"]
FILE_PATH = "data.json"

headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

# JSON —Ñ–∞–π–ª–¥—ã GitHub-—Ç–∞–Ω –∂“Ø–∫—Ç–µ—É
@st.cache_data
def load_json_from_github():
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        content = base64.b64decode(res.json()["content"]).decode("utf-8")
        sha = res.json()["sha"]
        return json.loads(content), sha
    else:
        st.error(f"‚ùå GitHub-—Ç–∞–Ω –¥–µ—Ä–µ–∫ –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ: {res.status_code}")
        return {}, None

# GitHub-“õ–∞ –∂–∞“£–∞ JSON –∂–∞–∑—É
def update_json_to_github(new_data, sha):
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
    updated_content = json.dumps(new_data, ensure_ascii=False, indent=2).encode("utf-8")
    b64_content = base64.b64encode(updated_content).decode("utf-8")

    data = {
        "message": "üîÑ –¢–µ—Ä–º–∏–Ω–¥–µ—Ä –∂–∞“£–∞—Ä—Ç—ã–ª–¥—ã",
        "content": b64_content,
        "sha": sha
    }
    response = requests.put(url, headers=headers, json=data)
    if response.status_code == 200 or response.status_code == 201:
        st.success("‚úÖ –¢–µ—Ä–º–∏–Ω–¥–µ—Ä GitHub-—Ç–∞ –∂–∞“£–∞—Ä—Ç—ã–ª–¥—ã!")
    else:
        st.error(f"‚ùå GitHub-“õ–∞ –∂–∞–∑—É “õ–∞—Ç–µ—Å—ñ: {response.text}")

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫", layout="wide")
st.title("üìò –ê–ö–¢ –∫—É—Ä—Å—ã: –≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫")

terms, sha = load_json_from_github()

# Excel –∂“Ø–∫—Ç–µ—É
uploaded_file = st.sidebar.file_uploader("üì§ Excel —Ñ–∞–π–ª –∂“Ø–∫—Ç–µ—É (xlsx)", type=["xlsx"])
if uploaded_file:
    try:
        df = pd.read_excel(uploaded_file)
        new_terms = []
        for _, row in df.iterrows():
            term = {
                'kk': row.get('kk', ''),
                'ru': row.get('ru', ''),
                'en': row.get('en', ''),
                'definition': {
                    'kk': row.get('definition_kk', ''),
                    'ru': row.get('definition_ru', ''),
                    'en': row.get('definition_en', '')
                },
                'example': {
                    'kk': row.get('example_kk', ''),
                    'ru': row.get('example_ru', ''),
                    'en': row.get('example_en', '')
                },
                'relations': {
                    'synonyms': str(row.get('relations_synonyms', '')).split(',') if row.get('relations_synonyms') else [],
                    'general_concept': row.get('relations_general_concept', ''),
                    'specific_concepts': str(row.get('relations_specific_concepts', '')).split(',') if row.get('relations_specific_concepts') else [],
                    'associative': str(row.get('relations_associative', '')).split(',') if row.get('relations_associative') else []
                }
            }
            new_terms.append(term)

        lecture_name = st.sidebar.selectbox("üìö “ö–∞–π –¥”ô—Ä—ñ—Å–∫–µ “õ–æ—Å—ã–ª–∞–¥—ã?", list(terms.keys()))
        if st.sidebar.button("‚ûï –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ “õ–æ—Å—É"):
            terms[lecture_name].extend(new_terms)
            with open("data.json", "w", encoding="utf-8") as f:
              json.dump(terms, f, ensure_ascii=False, indent=2)
            st.success(f"‚úÖ {len(new_terms)} –∂–∞“£–∞ —Ç–µ—Ä–º–∏–Ω “õ–æ—Å—ã–ª–¥—ã!")
            st.session_state['selected_term'] = None  # –∂–∞“£–∞–¥–∞–Ω –±–∞—Å—Ç–∞—É
            st.experimental_rerun()
            except Exception as e:
        st.error(f"‚ùå Excel –æ“õ—É “õ–∞—Ç–µ—Å—ñ: {e}")

# –Ü–∑–¥–µ—É —Ñ—É–Ω–∫—Ü–∏—è—Å—ã–Ω “õ–æ—Å—É
search_query = st.text_input("üîç –¢–µ—Ä–º–∏–Ω–¥—ñ —ñ–∑–¥–µ—É:", "").strip().lower()

def speak_buttons(term):
    kk = term.get('kk', '')
    ru = term.get('ru', '')
    en = term.get('en', '')
    html(f"""
        <div style='margin-bottom: 10px;'>
            <button onclick=\"speakRU()\" style='margin-right: 10px;'>üîä –û—Ä—ã—Å—à–∞</button>
            <button onclick=\"speakEN()\">üîä –ê“ì—ã–ª—à—ã–Ω—à–∞</button>
        </div>
        <script>
            function speakKK() {{
                var msg = new SpeechSynthesisUtterance("{kk}");
                msg.lang = "kk-KZ";
                window.speechSynthesis.speak(msg);
            }}
            function speakRU() {{
                var msg = new SpeechSynthesisUtterance("{ru}");
                msg.lang = "ru-RU";
                window.speechSynthesis.speak(msg);
            }}
            function speakEN() {{
                var msg = new SpeechSynthesisUtterance("{en}");
                msg.lang = "en-US";
                window.speechSynthesis.speak(msg);
            }}
        </script>
    """, height=60)
# –î”ô—Ä—ñ—Å —Ç–∞“£–¥–∞—É—ã
lecture = st.sidebar.radio("üìÇ –î”ô—Ä—ñ—Å —Ç–∞“£–¥–∞“£—ã–∑:", list(terms.keys()))
# –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –∫–∞—Ä—Ç–∞–Ω—ã –∫”©—Ä—É –±–∞—Ç—ã—Ä–º–∞—Å—ã
if st.sidebar.button("üìö –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –∫–∞—Ä—Ç–∞–Ω—ã –∫”©—Ä—É"):
    st.session_state['show_map'] = True
    components.html(
        """
        <html>
        <head><title>–°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –∫–∞—Ä—Ç–∞</title></head>
        <body>
        <h2>üìö –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –∫–∞—Ä—Ç–∞</h2>
        <div style='font-family:Arial;'>
        """ +
        ''.join([
            f"<p><b>{term.get('kk', '')}</b> - " +
            (f"üîÅ –°–∏–Ω–æ–Ω–∏–º–¥–µ—Ä: {', '.join(term.get('relations', {{}}).get('synonyms', []))} | " if term.get('relations', {{}}).get('synonyms') else '') +
            (f"üîº –ñ–∞–ª–ø—ã–ª–∞–º–∞: {term.get('relations', {{}}).get('general_concept')} | " if term.get('relations', {{}}).get('general_concept') else '') +
            (f"üîΩ –ê—Ä–Ω–∞–π—ã: {', '.join(term.get('relations', {{}}).get('specific_concepts', []))} | " if term.get('relations', {{}}).get('specific_concepts') else '') +
            (f"üîó “ö–∞—Ç—ã—Å—Ç—ã: {', '.join(term.get('relations', {{}}).get('associative', []))}" if term.get('relations', {{}}).get('associative') else '') +
            "</p>"
            for lecture_terms in terms.values() for term in lecture_terms
        ]) +
        """
        </div>
        </body>
        </html>
        """,
        height=500,
        scrolling=True
    )

if search_query:
    st.session_state['show_map'] = False
    st.header(f"üîé –Ü–∑–¥–µ—É –Ω”ô—Ç–∏–∂–µ–ª–µ—Ä—ñ: \"{search_query}\"")
    found_terms = []
    for lecture_name, term_list in terms.items():
        for term in term_list:
            if search_query in term.get('kk', '').lower() or search_query in term.get('ru', '').lower() or search_query in term.get('en', '').lower():
                found_terms.append((lecture_name, term))

    if not found_terms:
        st.warning("üõë –ë“±–ª —ñ–∑–¥–µ—É —Å“±—Ä–∞–Ω—ã—Å—ã–Ω–∞ —Å”ô–π–∫–µ—Å —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä —Ç–∞–±—ã–ª–º–∞–¥—ã.")
    else:
        for lecture_name, term in found_terms:
            term_text = f"{term.get('kk', '')} / {term.get('ru', '')} / {term.get('en', '')}"
            st.markdown(f"### üìÇ {lecture_name}<br>üñ• {term_text}", unsafe_allow_html=True)
            speak_buttons(term)

            with st.expander("üìñ –ê–Ω—ã“õ—Ç–∞–º–∞ / –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ / Definition"):
                if 'definition' in term:
                    st.markdown(f"**KK:** {term['definition'].get('kk', '–ñ–æ“õ')}")
                    st.markdown(f"**RU:** {term['definition'].get('ru', '–ù–µ—Ç')}")
                    st.markdown(f"**EN:** {term['definition'].get('en', 'No')}")
                else:
                    st.info("‚ùó –ë“±–ª —Ç–µ—Ä–º–∏–Ω “Ø—à—ñ–Ω –∞–Ω—ã“õ—Ç–∞–º–∞ –±–µ—Ä—ñ–ª–º–µ–≥–µ–Ω.")

            with st.expander("üí¨ –ú—ã—Å–∞–ª / –ü—Ä–∏–º–µ—Ä / Example"):
                if 'example' in term:
                    st.markdown(f"**KK:** {term['example'].get('kk', '–ñ–æ“õ')}")
                    st.markdown(f"**RU:** {term['example'].get('ru', '–ù–µ—Ç')}")
                    st.markdown(f"**EN:** {term['example'].get('en', 'No')}")
                else:
                    st.info("‚ùó –ë“±–ª —Ç–µ—Ä–º–∏–Ω “Ø—à—ñ–Ω –º—ã—Å–∞–ª –±–µ—Ä—ñ–ª–º–µ–≥–µ–Ω.")

            if term.get("image"):
                st.markdown(
                    f'<a href="{term["image"]}" target="_blank">'
                    f'<img src="{term["image"]}" width="200" style="border-radius:10px;" />'
                    f'</a>',
                    unsafe_allow_html=True
                )

            if term.get("source"):
                st.markdown(f"üîó [–î–µ—Ä–µ–∫–∫”©–∑ / –ò—Å—Ç–æ—á–Ω–∏–∫ / Source]({term['source']})")

            st.markdown("---")

# –¢–µ—Ä–º–∏–Ω —Ç—ñ–∑—ñ–º—ñ
if not search_query:
    st.write("### üìã –¢–µ—Ä–º–∏–Ω–¥–µ—Ä —Ç—ñ–∑—ñ–º—ñ:")

    page_size = 10
    total_terms = len(terms[lecture])
    total_pages = (total_terms + page_size - 1) // page_size

    page = st.number_input("üìÑ –ë–µ—Ç —Ç–∞“£–¥–∞—É", min_value=1, max_value=total_pages, step=1)

    start = (page - 1) * page_size
    end = start + page_size
    paginated_terms = terms[lecture][start:end]

    for i, term in enumerate(paginated_terms):
        name = term.get("kk", "")
        if st.button(f"üîπ {name}", key=f"term_{start + i}"):
            st.session_state['selected_term'] = name
# –¢–µ—Ä–º–∏–Ω –º”ô–ª—ñ–º–µ—Ç—ñ
selected = st.session_state.get("selected_term")
if selected:
    for term in terms[lecture]:
        if term.get("kk", "") == selected:
            term_text = f"{term.get('kk', '')} / {term.get('ru', '')} / {term.get('en', '')}"
            st.markdown(f"### üñ• {term_text}")

            st.markdown("**üìñ –ê–Ω—ã“õ—Ç–∞–º–∞:**")
            st.markdown(f"**KK:** {term['definition'].get('kk', '–ñ–æ“õ')}")
            st.markdown(f"**RU:** {term['definition'].get('ru', '–ù–µ—Ç')}")
            st.markdown(f"**EN:** {term['definition'].get('en', 'No')}")

            st.markdown("**üí¨ –ú—ã—Å–∞–ª:**")
            st.markdown(f"**KK:** {term['example'].get('kk', '–ñ–æ“õ')}")
            st.markdown(f"**RU:** {term['example'].get('ru', '–ù–µ—Ç')}")
            st.markdown(f"**EN:** {term['example'].get('en', 'No')}")

            if term.get("image"):
                st.image(term["image"], width=200)
            if term.get("source"):
                st.markdown(f"üîó [–î–µ—Ä–µ–∫–∫”©–∑ / –ò—Å—Ç–æ—á–Ω–∏–∫ / Source]({term['source']})")
