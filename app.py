import streamlit as st
import json
import pandas as pd
import requests
import base64
from difflib import get_close_matches
from streamlit.components.v1 import html

# ==================== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ====================
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = st.secrets["REPO_OWNER"]
REPO_NAME = st.secrets["REPO_NAME"]
FILE_PATH = "data.json"

headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

# ==================== –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
@st.cache_data
def load_github_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
    try:
        url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        content = base64.b64decode(response.json()["content"]).decode("utf-8")
        return json.loads(content), response.json()["sha"]
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return {}, None

def update_github(data, sha):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GitHub"""
    try:
        url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
        content = json.dumps(data, ensure_ascii=False, indent=2).encode("utf-8")
        
        response = requests.put(
            url,
            headers=headers,
            json={
                "message": "üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö",
                "content": base64.b64encode(content).decode("utf-8"),
                "sha": sha
            }
        )
        response.raise_for_status()
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {str(e)}")

def parse_excel(uploaded_file):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel-—Ñ–∞–π–ª–∞ —Å —Ç–µ—Ä–º–∏–Ω–∞–º–∏"""
    try:
        df = pd.read_excel(uploaded_file)
        return [
            {
                'kk': row.get('kk', ''),
                'ru': row.get('ru', ''),
                'en': row.get('en', ''),
                'definition': {
                    'kk': row.get('definition_kk', ''),
                    'ru': row.get('definition_ru', ''),
                    'en': row.get('definition_en', '')
                },
                'example': {
                    'kk': row.get('example_kk', ''),
                    'ru': row.get('example_ru', ''),
                    'en': row.get('example_en', '')
                },
                'relations': {
                    'synonyms': [s.strip() for s in str(row.get('synonyms', '')).split(',')],
                    'general': row.get('general_concept', ''),
                    'specific': [s.strip() for s in str(row.get('specific_concepts', '')).split(',')],
                    'associative': [s.strip() for s in str(row.get('associative', '')).split(',')]
                }
            }
            for _, row in df.iterrows()
        ]
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel: {str(e)}")
        return []

# ==================== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
def display_term(term):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–µ—Ä–º–∏–Ω–∞"""
    with st.container():
        st.markdown(f"### üåê {term.get('kk', '')}")
        
        # –í–∫–ª–∞–¥–∫–∏ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        tabs = st.tabs(["üìñ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "üí¨ –ü—Ä–∏–º–µ—Ä", "üîó –°–≤—è–∑–∏"])
        
        with tabs[0]:
            st.markdown(f"**KK:** {term['definition'].get('kk', '-')}")
            st.markdown(f"**RU:** {term['definition'].get('ru', '-')}")
            st.markdown(f"**EN:** {term['definition'].get('en', '-')}")
        
        with tabs[1]:
            st.markdown(f"**KK:** {term['example'].get('kk', '-')}")
            st.markdown(f"**RU:** {term['example'].get('ru', '-')}")
            st.markdown(f"**EN:** {term['example'].get('en', '-')}")
        
        with tabs[2]:
            cols = st.columns(2)
            with cols[0]:
                st.markdown("üîÅ **–°–∏–Ω–æ–Ω–∏–º—ã:**\n" + "\n".join(f"- {s}" for s in term['relations']['synonyms']))
                st.markdown("üîº **–û–±—â–µ–µ –ø–æ–Ω—è—Ç–∏–µ:**\n" + term['relations']['general'])
            with cols[1]:
                st.markdown("üîΩ **–ß–∞—Å—Ç–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è:**\n" + "\n".join(f"- {s}" for s in term['relations']['specific']))
                st.markdown("üîó **–ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏:**\n" + "\n".join(f"- {s}" for s in term['relations']['associative']))

# ==================== –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
def main():
    st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å", layout="wide")
    st.title("üìö –¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –ê–ö–¢")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    terms_data, sha = load_github_data()
    all_terms = [term for lecture in terms_data.values() for term in lecture]
    
    # ==================== –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å ====================
    with st.sidebar:
        st.header("‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ Excel
        uploaded_file = st.file_uploader("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å Excel", type=["xlsx"])
        if uploaded_file:
            new_terms = parse_excel(uploaded_file)
            if new_terms:
                selected_lecture = st.selectbox("üìö –í—ã–±–µ—Ä–∏—Ç–µ –ª–µ–∫—Ü–∏—é", list(terms_data.keys()))
                if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ—Ä–º–∏–Ω—ã"):
                    terms_data[selected_lecture].extend(new_terms)
                    update_github(terms_data, sha)
                    st.rerun()
        
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞
        if st.button("üåç –ü–æ–∫–∞–∑–∞—Ç—å —Å–≤—è–∑–∏"):
            html_content = "<div style='padding:20px; font-family:Arial;'>"
            html_content += "<h3>üîó –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏</h3>"
            for term in all_terms:
                html_content += f"<p><b>{term['kk']}</b> ‚Üí {', '.join(term['relations']['synonyms'] + term['relations']['specific'])}</p>"
            html_content += "</div>"
            html(html_content, height=500, scrolling=True)
    
    # ==================== –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
    # –ü–æ–∏—Å–∫ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    search_query = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —Ç–µ—Ä–º–∏–Ω–∞–º", help="–ò—â–∏—Ç–µ –Ω–∞ –ª—é–±–æ–º —è–∑—ã–∫–µ")
    filtered_terms = [
        term for term in all_terms
        if search_query.lower() in str(term).lower()
    ] if search_query else all_terms
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if filtered_terms:
        st.subheader(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(filtered_terms)}")
        for term in filtered_terms:
            display_term(term)
            st.divider()
    else:
        st.info("üîç –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")

if __name__ == "__main__":
    main()
