import streamlit as st
import json
import pandas as pd
import base64
import requests
from difflib import get_close_matches
from streamlit.components.v1 import html

# GitHub API –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = st.secrets["REPO_OWNER"]
REPO_NAME = st.secrets["REPO_NAME"]
FILE_PATH = "data.json"

headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

@st.cache_data
def load_json_from_github():
    """–ó–∞–≥—Ä—É–∑–∫–∞ JSON –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
    response = requests.get(url, headers=headers)
    
    if response.status_code == 200:
        content = base64.b64decode(response.json()["content"]).decode("utf-8")
        sha = response.json()["sha"]
        return json.loads(content), sha
    else:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {response.status_code}")
        return {}, None

def update_json_to_github(new_data, sha):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GitHub"""
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
    updated_content = json.dumps(new_data, ensure_ascii=False, indent=2).encode("utf-8")
    b64_content = base64.b64encode(updated_content).decode("utf-8")

    data = {
        "message": "üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏",
        "content": b64_content,
        "sha": sha
    }
    response = requests.put(url, headers=headers, json=data)
    
    if response.status_code in (200, 201):
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
    else:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {response.text}")

def display_term_info(term):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Ä–º–∏–Ω–µ"""
    term_text = f"{term.get('kk', '')} / {term.get('ru', '')} / {term.get('en', '')}"
    st.markdown(f"### üñ• {term_text}")
    
    with st.expander("üìñ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"):
        st.markdown(f"**KK:** {term.get('definition', {}).get('kk', '')}")
        st.markdown(f"**RU:** {term.get('definition', {}).get('ru', '')}")
        st.markdown(f"**EN:** {term.get('definition', {}).get('en', '')}")
    
    with st.expander("üí¨ –ü—Ä–∏–º–µ—Ä—ã"):
        st.markdown(f"**KK:** {term.get('example', {}).get('kk', '')}")
        st.markdown(f"**RU:** {term.get('example', {}).get('ru', '')}")
        st.markdown(f"**EN:** {term.get('example', {}).get('en', '')}")
    
    if relations := term.get("relations"):
        with st.expander("üîó –°–≤—è–∑–∏"):
            st.write(f"üîÅ –°–∏–Ω–æ–Ω–∏–º—ã: {', '.join(relations.get('synonyms', []))}")
            st.write(f"üîº –û–±—â–µ–µ –ø–æ–Ω—è—Ç–∏–µ: {relations.get('general_concept', '')}")
            st.write(f"üîΩ –ß–∞—Å—Ç–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è: {', '.join(relations.get('specific_concepts', []))}")
            st.write(f"üîó –ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏: {', '.join(relations.get('associative', []))}")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å", layout="wide")
st.title("üìò –≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
terms, sha = load_json_from_github()

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å
with st.sidebar:
    # –ó–∞–≥—Ä—É–∑–∫–∞ Excel —Ñ–∞–π–ª–∞
    uploaded_file = st.file_uploader("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å Excel", type=["xlsx"])
    if uploaded_file:
        try:
            df = pd.read_excel(uploaded_file)
            new_terms = []
            
            for _, row in df.iterrows():
                term = {
                    'kk': row.get('kk', ''),
                    'ru': row.get('ru', ''),
                    'en': row.get('en', ''),
                    'definition': {
                        'kk': row.get('definition_kk', ''),
                        'ru': row.get('definition_ru', ''),
                        'en': row.get('definition_en', '')
                    },
                    'example': {
                        'kk': row.get('example_kk', ''),
                        'ru': row.get('example_ru', ''),
                        'en': row.get('example_en', '')
                    },
                    'relations': {
                        'synonyms': row.get('relations_synonyms', '').split(',') if row.get('relations_synonyms') else [],
                        'general_concept': row.get('relations_general_concept', ''),
                        'specific_concepts': row.get('relations_specific_concepts', '').split(',') if row.get('relations_specific_concepts') else [],
                        'associative': row.get('relations_associative', '').split(',') if row.get('relations_associative') else []
                    }
                }
                new_terms.append(term)
            
            lecture = st.selectbox("üìö –í—ã–±–µ—Ä–∏—Ç–µ –ª–µ–∫—Ü–∏—é", list(terms.keys()))
            if st.button("‚ûï –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Ä–º–∏–Ω—ã"):
                terms[lecture].extend(new_terms)
                update_json_to_github(terms, sha)
                st.experimental_rerun()
        
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")

    # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞
    if st.button("üìö –ü–æ–∫–∞–∑–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –∫–∞—Ä—Ç—É"):
        html_content = """
        <html><body style='font-family:Arial; padding:20px;'>
            <h2>üìö –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞</h2>
            """ + "".join(
            f"<p><b>{term.get('kk', '')}</b> - " + 
            ", ".join(filter(None, [
                f"üîÅ {', '.join(term.get('relations', {}).get('synonyms', []))}" if term.get('relations', {}).get('synonyms') else None,
                f"üîº {term.get('relations', {}).get('general_concept', '')}" if term.get('relations', {}).get('general_concept') else None,
                f"üîΩ {', '.join(term.get('relations', {}).get('specific_concepts', []))}" if term.get('relations', {}).get('specific_concepts') else None,
                f"üîó {', '.join(term.get('relations', {}).get('associative', []))}" if term.get('relations', {}).get('associative') else None
            ])) + "</p>"
            for lecture_terms in terms.values() for term in lecture_terms
        ) + "</body></html>"
        
        html(html_content, height=500, scrolling=True)

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
# –ü–æ–∏—Å–∫ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
all_terms = [term for lecture_terms in terms.values() for term in lecture_terms]
search_query = st.text_input("üîç –ü–æ–∏—Å–∫ —Ç–µ—Ä–º–∏–Ω–∞:", placeholder="–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å...")

# –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
filtered_terms = [
    term for term in all_terms
    if search_query.lower() in term.get('kk', '').lower() or 
       search_query.lower() in term.get('ru', '').lower() or 
       search_query.lower() in term.get('en', '').lower()
]

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
if filtered_terms:
    st.subheader(f"üìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ ({len(filtered_terms})")
    for term in filtered_terms:
        display_term_info(term)
        st.markdown("---")
else:
    st.info("üîç –¢–µ—Ä–º–∏–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å.")

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–æ–≤ –ø–æ –ª–µ–∫—Ü–∏—è–º
lecture = st.sidebar.radio("üìÇ –í—ã–±–µ—Ä–∏—Ç–µ –ª–µ–∫—Ü–∏—é:", list(terms.keys()))
st.subheader(f"üìö –¢–µ—Ä–º–∏–Ω—ã –ª–µ–∫—Ü–∏–∏: {lecture}")

for term in terms[lecture]:
    if st.button(f"üîπ {term.get('kk', '')}", key=f"term_{term.get('kk', '')}"):
        display_term_info(term)
        st.markdown("---")
