import streamlit as st
import json
import pandas as pd
import requests
import base64
from difflib import get_close_matches
from streamlit.components.v1 import html

# ==================== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ====================
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = st.secrets["REPO_OWNER"]
REPO_NAME = st.secrets["REPO_NAME"]
FILE_PATH = "data.json"

headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

# ==================== –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
@st.cache_data(ttl=60, show_spinner=False)
def load_github_data():
    try:
        url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        content = base64.b64decode(response.json()["content"]).decode("utf-8")
        return json.loads(content), response.json()["sha"]
    except Exception as e:
        st.error(f"‚ùå –î–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ: {str(e)}")
        return {}, None

def update_github(data):
    """GitHub-—Ç–∞ –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –∂–∞“£–∞—Ä—Ç—É (–∞–≤—Ç–æ–º–∞—Ç—Ç—ã SHA –∞–ª—É –∞—Ä“õ—ã–ª—ã)"""
    try:
        # 1. –ê“ì—ã–º–¥–∞“ì—ã SHA-–Ω—ã –∞–ª—É
        current_content = requests.get(
            f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}",
            headers=headers
        ).json()
        sha = current_content.get("sha")

        # 2. –ñ–∞“£–∞ –¥–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –∂—ñ–±–µ—Ä—É
        response = requests.put(
            f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}",
            headers=headers,
            json={
                "message": "–¢–µ—Ä–º–∏–Ω–¥–µ—Ä –∂–∞“£–∞—Ä—Ç—ã–ª–¥—ã",
                "content": base64.b64encode(json.dumps(data, ensure_ascii=False).encode()).decode(),
                "sha": sha  # –ê“ì—ã–º–¥–∞“ì—ã SHA “õ–æ–ª–¥–∞–Ω—É
            }
        )

        if response.status_code == 200:
            st.success("‚úÖ –¢–µ—Ä–º–∏–Ω–¥–µ—Ä —Å”ô—Ç—Ç—ñ —Å–∞“õ—Ç–∞–ª–¥—ã!")
            return True
        else:
            st.error(f"‚ùå GitHub “õ–∞—Ç–µ—Å—ñ: {response.json().get('message')}")
            return False

    except Exception as e:
        st.error(f"‚ùå –°–∞“õ—Ç–∞—É “õ–∞—Ç–µ—Å—ñ: {str(e)}")
        return False

def parse_excel(uploaded_file):
    """Excel —Ñ–∞–π–ª–¥—ã –¥“±—Ä—ã—Å –ø–∞—Ä—Å–∏–Ω–≥ –∂–∞—Å–∞—É (–∂–∞“£–∞—Ä—Ç—ã–ª“ì–∞–Ω –Ω“±—Å“õ–∞—Å—ã)"""
    try:
        df = pd.read_excel(uploaded_file)
        
        # –ú—ñ–Ω–¥–µ—Ç—Ç—ñ –±–∞“ì–∞–Ω–¥–∞—Ä–¥—ã —Ç–µ–∫—Å–µ—Ä—É
        required_columns = ['kk', 'ru', 'en']
        missing = [col for col in required_columns if col not in df.columns]
        if missing:
            st.error(f"‚ùå “ö–∞–∂–µ—Ç—Ç—ñ –±–∞“ì–∞–Ω–¥–∞—Ä –∂–æ“õ: {', '.join(missing)}")
            return []

        new_terms = []
        for _, row in df.iterrows():
            # –ù–µ–≥—ñ–∑–≥—ñ –∞“õ–ø–∞—Ä–∞—Ç
            term = {
                'kk': str(row['kk']).strip(),
                'ru': str(row['ru']).strip(),
                'en': str(row['en']).strip(),
                'definition': {
                    'kk': str(row.get('definition_kk', '')).strip(),
                    'ru': str(row.get('definition_ru', '')).strip(),
                    'en': str(row.get('definition_en', '')).strip()
                },
                'example': {
                    'kk': str(row.get('example_kk', '')).strip(),
                    'ru': str(row.get('example_ru', '')).strip(),
                    'en': str(row.get('example_en', '')).strip()
                },
                'relations': {
                    'synonyms': [s.strip() for s in str(row.get('synonyms', '')).split(',') if s.strip()],
                    'general_concept': str(row.get('general_concept', '')).strip(),
                    'specific_concepts': [s.strip() for s in str(row.get('specific_concepts', '')).split(',') if s.strip()],
                    'associative': [s.strip() for s in str(row.get('associative', '')).split(',') if s.strip()]
                }
            }
            
            # –ü—É—Å—Ç—ã“õ ”©—Ä—ñ—Å—Ç–µ—Ä–¥—ñ ”©—à—ñ—Ä—É
            for key in ['definition', 'example']:
                term[key] = {k: v for k, v in term[key].items() if v}
            
            new_terms.append(term)
        
        return new_terms

    except Exception as e:
        st.error(f"‚ùå Excel “õ–∞—Ç–µ—Å—ñ: {str(e)}")
        return []
# ==================== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
def display_term_compact(term, index):
    """–¢–µ—Ä–º–∏–Ω–Ω—ñ“£ “õ—ã—Å“õ–∞—à–∞ –∫”©—Ä—ñ–Ω—ñ—Å—ñ"""
    kk_title = term.get('kk', '–ê—Ç–∞—É—ã –∂–æ“õ')
    unique_key = f"compact_{index}_{kk_title[:10]}"  # –ò–Ω–¥–µ–∫—Å –ø–µ–Ω –∞—Ç–∞—É–¥–∞–Ω –∫—ñ–ª—Ç
    if st.button(f"üîπ {kk_title}", key=unique_key):
        st.session_state.selected_term = term

def display_term_full(term):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Ä–º–∏–Ω–µ"""
    with st.expander(f"üìò {term.get('kk', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}", expanded=True):
        tabs = st.tabs(["üìñ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "üí¨ –ü—Ä–∏–º–µ—Ä", "üîó –°–≤—è–∑–∏"])
        
        definition = term.get('definition', {})
        example = term.get('example', {})
        relations = term.get('relations', {})

        with tabs[0]:
            st.markdown(f"**KK:** {definition.get('kk', '-')}")
            st.markdown(f"**RU:** {definition.get('ru', '-')}")
            st.markdown(f"**EN:** {definition.get('en', '-')}")
        
        with tabs[1]:
            st.markdown(f"**KK:** {example.get('kk', '-')}")
            st.markdown(f"**RU:** {example.get('ru', '-')}")
            st.markdown(f"**EN:** {example.get('en', '-')}")
        
        with tabs[2]:
            cols = st.columns(2)
            with cols[0]:
                st.markdown("üîÅ **–°–∏–Ω–æ–Ω–∏–º—ã:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('synonyms', [])
                ))
                st.markdown("üîº **–û–±—â–µ–µ –ø–æ–Ω—è—Ç–∏–µ:**\n" + relations.get('general', '-'))
            with cols[1]:
                st.markdown("üîΩ **–ß–∞—Å—Ç–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('specific', [])
                ))
                st.markdown("üîó **–ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('associative', [])
                ))

# ==================== –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
def main():
    st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫", layout="wide")
    st.title("üìò –ê–ö–¢ –∫—É—Ä—Å—ã: –≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    terms_data, sha = load_github_data()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if not terms_data or not isinstance(terms_data, dict):
        st.error("‚ùå –î–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ –Ω–µ–º–µ—Å–µ “õ–∞—Ç–µ —Ñ–æ—Ä–º–∞—Ç")
        return
    
    all_terms = [term for lecture in terms_data.values() for term in lecture]
    
    # ==================== –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å ====================
    with st.sidebar:
        uploaded_file = st.file_uploader("üì§ Excel —Ñ–∞–π–ª –∂“Ø–∫—Ç–µ—É", type=["xlsx"])
        if uploaded_file:
            new_terms = parse_excel(uploaded_file)
            if new_terms:
                st.success(f"‚úÖ {len(new_terms)} –∂–∞“£–∞ —Ç–µ—Ä–º–∏–Ω —Ç–∞–±—ã–ª–¥—ã!")
                
                # –¢–∞“õ—ã—Ä—ã–ø—Ç—ã —Ç–∞“£–¥–∞—É
                lecture_options = list(terms_data.keys()) + ["+ –ñ–ê“¢–ê –¢–ê“ö–´–†–´–ü"]
                selected_lecture = st.selectbox(
                    "üìö –¢–∞“õ—ã—Ä—ã–ø —Ç–∞“£–¥–∞“£—ã–∑:", 
                    lecture_options,
                    index=0
                )

                if selected_lecture == "+ –ñ–ê“¢–ê –¢–ê“ö–´–†–´–ü":
                    new_lecture_name = st.text_input("–ñ–∞“£–∞ —Ç–∞“õ—ã—Ä—ã–ø –∞—Ç–∞—É—ã:")
                    if new_lecture_name:
                        selected_lecture = new_lecture_name
                        terms_data[selected_lecture] = []  
                
                if selected_lecture not in terms_data:
                    terms_data[selected_lecture] = []  # –ö—ñ–ª—Ç –∂–æ“õ –±–æ–ª—Å–∞ –∂–∞—Å–∞—É

                if st.button("üíæ –°–∞“õ—Ç–∞—É"):
                     st.cache_data.clear()
                     terms_data, _ = load_github_data()
                     terms_data[selected_lecture].extend(new_terms)
                     if update_github(terms_data):
                        st.rerun()
        
        # –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –∫–∞—Ä—Ç–∞
        if st.button("üåç –ë–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä–¥—ã –∫”©—Ä—Å–µ—Ç—É"):
            html_content = "<div style='padding:20px; font-family:Arial;'>"
            html_content += "<h3>üîó –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –±–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä</h3>"
            
            for lecture in terms_data.values():
                for term in lecture:
                    try:
                        kk = term.get('kk', '–ê—Ç–∞—É—ã –∂–æ“õ')
                        relations = term.get('relations', {})
                        elements = []
                        if 'synonyms' in relations:
                            elements.extend(relations['synonyms'])
                        if 'specific' in relations:
                            elements.extend(relations['specific'])
                        html_content += f"<p><b>{kk}</b> ‚Üí {', '.join(elements)}</p>"
                    except Exception as e:
                        continue
            
            html_content += "</div>"
            html(html_content, height=500, scrolling=True)

    # ==================== –ù–µ–≥—ñ–∑–≥—ñ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
    view_mode = st.radio("üîç –ö”©—Ä—ñ–Ω—É —Ä–µ–∂–∏–º—ñ:", 
                        ["üìÇ –¢–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞", "üîé –ë–∞—Ä–ª—ã“õ —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä–¥–µ–Ω —ñ–∑–¥–µ—É"], 
                        horizontal=True)

    if view_mode == "üìÇ –¢–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞":
        # –¢–∞“õ—ã—Ä—ã–ø—Ç—ã —Ç–∞“£–¥–∞—É
        selected_lecture = st.selectbox(
            "üìö –¢–∞“õ—ã—Ä—ã–ø—Ç—ã —Ç–∞“£–¥–∞“£—ã–∑:",
            list(terms_data.keys()),
            index=0,
            key="lecture_selector"
        )
    
        # –§–∏–ª—å—Ç—Ä–ª–µ—Ä
        st.subheader(f"üìñ –¢–∞“õ—ã—Ä—ã–ø: {selected_lecture}")
        
        # 1. ”ò—Ä—ñ–ø –±–æ–π—ã–Ω—à–∞ —Å“Ø–∑–≥—ñ
        initial_terms = terms_data[selected_lecture]
        letters = sorted({term['kk'][0].upper() for term in initial_terms if term.get('kk')})
        selected_letter = st.selectbox("üî§ ”ò—Ä—ñ–ø –±–æ–π—ã–Ω—à–∞ —Å“Ø–∑–≥—ñ", ["–ë–∞—Ä–ª—ã“ì—ã"] + letters)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        filtered_terms = [
            term for term in initial_terms
            if selected_letter == "–ë–∞—Ä–ª—ã“ì—ã" or term.get('kk', '').upper().startswith(selected_letter)
        ]
    
        # 2. –°“±—Ä—ã–ø—Ç–∞—É –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä—ñ
        col1, col2 = st.columns([3, 2])
        with col1:
            sort_option = st.selectbox(
                "üîÉ –°“±—Ä—ã–ø—Ç–∞—É —Ç“Ø—Ä—ñ",
                options=[
                    "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–ê-–Ø)",
                    "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–Ø-–ê)",
                    "–ú—ã—Å–∞–ª–¥–∞—Ä—ã –±–∞—Ä–ª–∞—Ä –∞–ª–¥—ã–º–µ–Ω"
                ],
                index=0
            )
        
        # –°“±—Ä—ã–ø—Ç–∞—É –ª–æ–≥–∏–∫–∞—Å—ã
        if sort_option == "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–ê-–Ø)":
            filtered_terms.sort(key=lambda x: x.get('kk', ''))
        elif sort_option == "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–Ø-–ê)":
            filtered_terms.sort(key=lambda x: x.get('kk', ''), reverse=True)
        elif sort_option == "–ú—ã—Å–∞–ª–¥–∞—Ä—ã –±–∞—Ä–ª–∞—Ä –∞–ª–¥—ã–º–µ–Ω":
            filtered_terms.sort(key=lambda x: len(x.get('example', {}).get('kk', '')), reverse=True)
    
        # –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ –∫”©—Ä—Å–µ—Ç—É
        st.write(f"üî¢ –ñ–∞–ª–ø—ã —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä: {len(filtered_terms)}")
        
        for idx, term in enumerate(filtered_terms):
            display_term_compact(term, idx)
       # –¢–æ–ª—ã“õ –∞“õ–ø–∞—Ä–∞—Ç—Ç—ã –∫”©—Ä—Å–µ—Ç—É
        if st.session_state.get('selected_term'):
            display_term_full(st.session_state.selected_term)
            if st.button("‚ùå –ñ–∞–±—É"):
                del st.session_state.selected_term
                st.rerun()
    else:
        # –ë–∞—Ä–ª—ã“õ —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä–¥–µ–Ω —ñ–∑–¥–µ—É
        search_query = st.text_input("üîç –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ —ñ–∑–¥–µ—É", help="–ö–µ–∑ –∫–µ–ª–≥–µ–Ω —Ç—ñ–ª–¥–µ —ñ–∑–¥–µ“£—ñ–∑")
        filtered_terms = [
            term for term in all_terms
            if search_query.lower() in str(term).lower()
        ] if search_query else all_terms
        
        if filtered_terms:
            st.subheader(f"üìö –¢–∞–±—ã–ª–¥—ã: {len(filtered_terms)} —Ç–µ—Ä–º–∏–Ω")
            for idx, term in enumerate(filtered_terms):  # <-- enumerate “õ–æ—Å—ã–ª–¥—ã
                display_term_compact(term, idx)  # <-- –∏–Ω–¥–µ–∫—Å –±–µ—Ä—ñ–ª–¥—ñ
                #st.divider()
        else:
            st.info("üîç –ï—à—Ç–µ“£–µ —Ç–∞–±—ã–ª“ì–∞–Ω –∂–æ“õ. –Ü–∑–¥–µ—É —Å“±—Ä–∞–Ω—ã—Å—ã–Ω ”©–∑–≥–µ—Ä—Ç—ñ“£—ñ–∑.")
if __name__ == "__main__":
    main()
