import streamlit as st
import json
import pandas as pd
import requests
import base64
from difflib import get_close_matches
from streamlit.components.v1 import html

# ==================== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ====================
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = st.secrets["REPO_OWNER"]
REPO_NAME = st.secrets["REPO_NAME"]
FILE_PATH = "data.json"

headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

# ==================== –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
@st.cache_data
def load_github_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
    try:
        url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        content = base64.b64decode(response.json()["content"]).decode("utf-8")
        return json.loads(content), response.json()["sha"]
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return {}, None

def update_github(data, sha):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GitHub"""
    try:
        url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
        content = json.dumps(data, ensure_ascii=False, indent=2).encode("utf-8")
        
        response = requests.put(
            url,
            headers=headers,
            json={
                "message": "üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö",
                "content": base64.b64encode(content).decode("utf-8"),
                "sha": sha
            }
        )
        response.raise_for_status()
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {str(e)}")

def parse_excel(uploaded_file):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel-—Ñ–∞–π–ª–∞ —Å —Ç–µ—Ä–º–∏–Ω–∞–º–∏"""
    try:
        df = pd.read_excel(uploaded_file)
        return [
            {
                'kk': row.get('kk', ''),
                'ru': row.get('ru', ''),
                'en': row.get('en', ''),
                'definition': {
                    'kk': row.get('definition_kk', ''),
                    'ru': row.get('definition_ru', ''),
                    'en': row.get('definition_en', '')
                },
                'example': {
                    'kk': row.get('example_kk', ''),
                    'ru': row.get('example_ru', ''),
                    'en': row.get('example_en', '')
                },
                'relations': {
                    'synonyms': [s.strip() for s in str(row.get('synonyms', '')).split(',')],
                    'general': [s.strip() for s in str(row.get('general_concept', '')).split(',')],
                    'specific': [s.strip() for s in str(row.get('specific_concepts', '')).split(',')],
                    'associative': [s.strip() for s in str(row.get('associative', '')).split(',')]
                }
            }
            for _, row in df.iterrows()
        ]
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel: {str(e)}")
        return []

# ==================== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
def display_term_compact(term, index):
    """–¢–µ—Ä–º–∏–Ω–Ω—ñ“£ “õ—ã—Å“õ–∞—à–∞ –∫”©—Ä—ñ–Ω—ñ—Å—ñ"""
    kk_title = term.get('kk', '–ê—Ç–∞—É—ã –∂–æ“õ')
    unique_key = f"compact_{index}_{kk_title[:10]}"  # –ò–Ω–¥–µ–∫—Å –ø–µ–Ω –∞—Ç–∞—É–¥–∞–Ω –∫—ñ–ª—Ç
    if st.button(f"üîπ {kk_title}", key=unique_key):
        st.session_state.selected_term = term

def display_term_full(term):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Ä–º–∏–Ω–µ"""
    with st.expander(f"üìò {term.get('kk', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}", expanded=True):
        tabs = st.tabs(["üìñ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "üí¨ –ü—Ä–∏–º–µ—Ä", "üîó –°–≤—è–∑–∏"])
        
        definition = term.get('definition', {})
        example = term.get('example', {})
        relations = term.get('relations', {})

        with tabs[0]:
            st.markdown(f"**KK:** {definition.get('kk', '-')}")
            st.markdown(f"**RU:** {definition.get('ru', '-')}")
            st.markdown(f"**EN:** {definition.get('en', '-')}")
        
        with tabs[1]:
            st.markdown(f"**KK:** {example.get('kk', '-')}")
            st.markdown(f"**RU:** {example.get('ru', '-')}")
            st.markdown(f"**EN:** {example.get('en', '-')}")
        
        with tabs[2]:
            cols = st.columns(2)
            with cols[0]:
                st.markdown("üîÅ **–°–∏–Ω–æ–Ω–∏–º—ã:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('synonyms', [])
                ))
                st.markdown("üîº **–û–±—â–µ–µ –ø–æ–Ω—è—Ç–∏–µ:**\n" + relations.get('general', '-'))
            with cols[1]:
                st.markdown("üîΩ **–ß–∞—Å—Ç–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('specific', [])
                ))
                st.markdown("üîó **–ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('associative', [])
                ))

# ==================== –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
def main():
    st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫", layout="wide")
    st.title("üìò –ê–ö–¢ –∫—É—Ä—Å—ã: –≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    terms_data, sha = load_github_data()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if not terms_data or not isinstance(terms_data, dict):
        st.error("‚ùå –î–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ –Ω–µ–º–µ—Å–µ “õ–∞—Ç–µ —Ñ–æ—Ä–º–∞—Ç")
        return
    
    all_terms = [term for lecture in terms_data.values() for term in lecture]
    
    # ==================== –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å ====================
    with st.sidebar:
        st.header("‚öôÔ∏è –î–µ—Ä–µ–∫—Ç–µ—Ä–¥—ñ –±–∞—Å“õ–∞—Ä—É")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ Excel
        uploaded_file = st.file_uploader("üì§ Excel —Ñ–∞–π–ª –∂“Ø–∫—Ç–µ—É", type=["xlsx"])
        if uploaded_file:
            new_terms = parse_excel(uploaded_file)
            if new_terms:
                selected_lecture = st.selectbox("üìö –î”ô—Ä—ñ—Å —Ç–∞“£–¥–∞“£—ã–∑", list(terms_data.keys()))
                if st.button("üíæ –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ —Å–∞“õ—Ç–∞—É"):
                    terms_data[selected_lecture].extend(new_terms)
                    update_github(terms_data, sha)
                    st.rerun()
        
        # –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –∫–∞—Ä—Ç–∞
        if st.button("üåç –ë–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä–¥—ã –∫”©—Ä—Å–µ—Ç—É"):
            html_content = "<div style='padding:20px; font-family:Arial;'>"
            html_content += "<h3>üîó –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –±–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä</h3>"
            
            for lecture in terms_data.values():
                for term in lecture:
                    try:
                        kk = term.get('kk', '–ê—Ç–∞—É—ã –∂–æ“õ')
                        relations = term.get('relations', {})
                        elements = []
                        if 'synonyms' in relations:
                            elements.extend(relations['synonyms'])
                        if 'specific' in relations:
                            elements.extend(relations['specific'])
                        html_content += f"<p><b>{kk}</b> ‚Üí {', '.join(elements)}</p>"
                    except Exception as e:
                        continue
            
            html_content += "</div>"
            html(html_content, height=500, scrolling=True)

    # ==================== –ù–µ–≥—ñ–∑–≥—ñ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
    view_mode = st.radio("üîç –ö”©—Ä—ñ–Ω—É —Ä–µ–∂–∏–º—ñ:", 
                        ["üìÇ –¢–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞", "üîé –ë–∞—Ä–ª—ã“õ —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä–¥–µ–Ω —ñ–∑–¥–µ—É"], 
                        horizontal=True)

    if view_mode == "üìÇ –¢–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞":
        # –¢–∞“õ—ã—Ä—ã–ø—Ç—ã —Ç–∞“£–¥–∞—É
        selected_lecture = st.selectbox(
            "üìö –¢–∞“õ—ã—Ä—ã–ø—Ç—ã —Ç–∞“£–¥–∞“£—ã–∑:",
            list(terms_data.keys()),
            index=0,
            key="lecture_selector"
        )
    
        # –§–∏–ª—å—Ç—Ä–ª–µ—Ä
        st.subheader(f"üìñ –¢–∞“õ—ã—Ä—ã–ø: {selected_lecture}")
        
        # 1. ”ò—Ä—ñ–ø –±–æ–π—ã–Ω—à–∞ —Å“Ø–∑–≥—ñ
        initial_terms = terms_data[selected_lecture]
        letters = sorted({term['kk'][0].upper() for term in initial_terms if term.get('kk')})
        selected_letter = st.selectbox("üî§ ”ò—Ä—ñ–ø –±–æ–π—ã–Ω—à–∞ —Å“Ø–∑–≥—ñ", ["–ë–∞—Ä–ª—ã“ì—ã"] + letters)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        filtered_terms = [
            term for term in initial_terms
            if selected_letter == "–ë–∞—Ä–ª—ã“ì—ã" or term.get('kk', '').upper().startswith(selected_letter)
        ]
    
        # 2. –°“±—Ä—ã–ø—Ç–∞—É –ø–∞—Ä–∞–º–µ—Ç—Ä–ª–µ—Ä—ñ
        col1, col2 = st.columns([3, 2])
        with col1:
            sort_option = st.selectbox(
                "üîÉ –°“±—Ä—ã–ø—Ç–∞—É —Ç“Ø—Ä—ñ",
                options=[
                    "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–ê-–Ø)",
                    "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–Ø-–ê)",
                    "–ú—ã—Å–∞–ª–¥–∞—Ä—ã –±–∞—Ä–ª–∞—Ä –∞–ª–¥—ã–º–µ–Ω"
                ],
                index=0
            )
        
        # –°“±—Ä—ã–ø—Ç–∞—É –ª–æ–≥–∏–∫–∞—Å—ã
        if sort_option == "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–ê-–Ø)":
            filtered_terms.sort(key=lambda x: x.get('kk', ''))
        elif sort_option == "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–Ø-–ê)":
            filtered_terms.sort(key=lambda x: x.get('kk', ''), reverse=True)
        elif sort_option == "–ú—ã—Å–∞–ª–¥–∞—Ä—ã –±–∞—Ä–ª–∞—Ä –∞–ª–¥—ã–º–µ–Ω":
            filtered_terms.sort(key=lambda x: len(x.get('example', {}).get('kk', '')), reverse=True)
    
        # –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ –∫”©—Ä—Å–µ—Ç—É
        st.write(f"üî¢ –ñ–∞–ª–ø—ã —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä: {len(filtered_terms)}")
        
        for idx, term in enumerate(filtered_terms):
            display_term_compact(term, idx)
       # –¢–æ–ª—ã“õ –∞“õ–ø–∞—Ä–∞—Ç—Ç—ã –∫”©—Ä—Å–µ—Ç—É
        if st.session_state.get('selected_term'):
            display_term_full(st.session_state.selected_term)
            if st.button("‚ùå –ñ–∞–±—É"):
                del st.session_state.selected_term
                st.rerun()
    else:
        # –ë–∞—Ä–ª—ã“õ —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä–¥–µ–Ω —ñ–∑–¥–µ—É
        search_query = st.text_input("üîç –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ —ñ–∑–¥–µ—É", help="–ö–µ–∑ –∫–µ–ª–≥–µ–Ω —Ç—ñ–ª–¥–µ —ñ–∑–¥–µ“£—ñ–∑")
        filtered_terms = [
            term for term in all_terms
            if search_query.lower() in str(term).lower()
        ] if search_query else all_terms
        
        if filtered_terms:
            st.subheader(f"üìö –¢–∞–±—ã–ª–¥—ã: {len(filtered_terms)} —Ç–µ—Ä–º–∏–Ω")
            for idx, term in enumerate(filtered_terms):  # <-- enumerate “õ–æ—Å—ã–ª–¥—ã
                display_term_compact(term, idx)  # <-- –∏–Ω–¥–µ–∫—Å –±–µ—Ä—ñ–ª–¥—ñ
                #st.divider()
        else:
            st.info("üîç –ï—à—Ç–µ“£–µ —Ç–∞–±—ã–ª“ì–∞–Ω –∂–æ“õ. –Ü–∑–¥–µ—É —Å“±—Ä–∞–Ω—ã—Å—ã–Ω ”©–∑–≥–µ—Ä—Ç—ñ“£—ñ–∑.")
if __name__ == "__main__":
    main()
