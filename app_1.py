import streamlit as st
import json
import pandas as pd
import requests
import base64
from difflib import get_close_matches
from streamlit.components.v1 import html

# ==================== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ====================
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = st.secrets["REPO_OWNER"]
REPO_NAME = st.secrets["REPO_NAME"]
FILE_PATH = "data.json"
ITEMS_PER_PAGE = 30  
COLUMN_ITEMS = 10 
headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}
KAZ_ALPHABET = [
    '”ò', '–Ü', '“¢', '“í', '“Æ', '“∞', '“ö', '”®', '“∫',
    '–ê', '–ë', '–í', '–ì', '–î', '–ï', '–ñ', '–ó',
    '–ò', '–ô', '–ö', '–õ', '–ú', '–ù', '–û', '–ü',
    '–†', '–°', '–¢', '–£', '–§', '–•', '–¶', '–ß',
    '–®', '–©', '–´', '–≠', '–Æ', '–Ø'
]
# ==================== –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
@st.cache_data(ttl=60, show_spinner=False)
def load_github_data():
    try:
        url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        content = base64.b64decode(response.json()["content"]).decode("utf-8")
        return json.loads(content), response.json()["sha"]
    except Exception as e:
        st.error(f"‚ùå –î–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ: {str(e)}")
        return {}, None

def update_github(data):
    try:
        current_content = requests.get(
            f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}",
            headers=headers
        ).json()
        sha = current_content.get("sha")

        response = requests.put(
            f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}",
            headers=headers,
            json={
                "message": "–¢–µ—Ä–º–∏–Ω–¥–µ—Ä –∂–∞“£–∞—Ä—Ç—ã–ª–¥—ã",
                "content": base64.b64encode(json.dumps(data, ensure_ascii=False).encode()).decode(),
                "sha": sha
            }
        )

        if response.status_code == 200:
            st.success("‚úÖ –¢–µ—Ä–º–∏–Ω–¥–µ—Ä —Å”ô—Ç—Ç—ñ —Å–∞“õ—Ç–∞–ª–¥—ã!")
            return True
        else:
            st.error(f"‚ùå GitHub “õ–∞—Ç–µ—Å—ñ: {response.json().get('message')}")
            return False
    except Exception as e:
        st.error(f"‚ùå –°–∞“õ—Ç–∞—É “õ–∞—Ç–µ—Å—ñ: {str(e)}")
        return False

def parse_excel(uploaded_file):
    try:
        df = pd.read_excel(uploaded_file)
        required_columns = ['kk', 'ru', 'en']
        missing = [col for col in required_columns if col not in df.columns]
        if missing:
            st.error(f"‚ùå “ö–∞–∂–µ—Ç—Ç—ñ –±–∞“ì–∞–Ω–¥–∞—Ä –∂–æ“õ: {', '.join(missing)}")
            return []

        new_terms = []
        for _, row in df.iterrows():
            term = {
                'kk': str(row['kk']).strip(),
                'ru': str(row['ru']).strip(),
                'en': str(row['en']).strip(),
                'definition': {
                    'kk': str(row.get('definition_kk', '')).strip(),
                    'ru': str(row.get('definition_ru', '')).strip(),
                    'en': str(row.get('definition_en', '')).strip()
                },
                'example': {
                    'kk': str(row.get('example_kk', '')).strip(),
                    'ru': str(row.get('example_ru', '')).strip(),
                    'en': str(row.get('example_en', '')).strip()
                },
                'relations': {
                    'synonyms': [s.strip() for s in str(row.get('synonyms', '')).split(',') if s.strip()],
                    'general_concept': str(row.get('general_concept', '')).strip(),
                    'specific_concepts': [s.strip() for s in str(row.get('specific_concepts', '')).split(',') if s.strip()],
                    'associative': [s.strip() for s in str(row.get('associative', '')).split(',') if s.strip()]
                }
            }
            for key in ['definition', 'example']:
                term[key] = {k: v for k, v in term[key].items() if v}
            new_terms.append(term)
        return new_terms
    except Exception as e:
        st.error(f"‚ùå Excel “õ–∞—Ç–µ—Å—ñ: {str(e)}")
        return []

# ==================== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
def display_term_compact(term, index):
    kk_title = term.get('kk', '–ê—Ç–∞—É—ã –∂–æ“õ')
    unique_key = f"compact_{index}_{kk_title[:10]}"
    if st.button(f"üîπ {kk_title}", key=unique_key):
        st.session_state.selected_term = term

def display_terms_in_columns(terms, start_idx):
    col1, col2, col3 = st.columns(3)
    
    with col1:
        for idx_in_page, term in enumerate(terms[:COLUMN_ITEMS]):
            global_index = start_idx + idx_in_page
            display_term_compact(term, global_index)
    
    with col2:
        for idx_in_page, term in enumerate(terms[COLUMN_ITEMS:COLUMN_ITEMS*2], start=COLUMN_ITEMS):
            global_index = start_idx + idx_in_page
            display_term_compact(term, global_index)
    
    with col3:
        for idx_in_page, term in enumerate(terms[COLUMN_ITEMS*2:], start=COLUMN_ITEMS*2):
            global_index = start_idx + idx_in_page
            display_term_compact(term, global_index)

def display_term_full(term):
    FLAGS = {
        'kk': 'https://img.icons8.com/?size=100&id=bTwapbmoLtc6&format=png&color=000000',    # “ö–∞–∑–∞“õ—Å—Ç–∞–Ω
        'ru': 'https://img.icons8.com/?size=100&id=hT4UdesmXlvG&format=png&color=000000',    # –†–µ—Å–µ–π
        'en': 'https://img.icons8.com/?size=100&id=Halaubi1vvya&format=png&color=000000'     # –ê“ö–®
    }
    term_html = []
    for lang, url in FLAGS.items():
        if term.get(lang):
            term_html.append(
                f'<span style="vertical-align: middle;">'
                f'<img src="{url}" style="height: 18px; margin-right: 5px;">'
                f'{term[lang]}'
                f'</span>'
            )
    term_text = '  |  '.join(term_html) or '–¢–µ—Ä–º–∏–Ω –∞—Ç–∞—É—ã –∂–æ“õ'        
    with st.expander(f"üìò –¢–µ—Ä–º–∏–Ω –∞“õ–ø–∞—Ä–∞—Ç—ã", expanded=True):
        st.markdown(f"""
        <div style="font-size: 1.5rem; margin-bottom: 15px;">
            {term_text}
        </div>
        """, unsafe_allow_html=True)
        cols = st.columns(5)
        with cols[0]:
            if term.get('kk'):
                if st.button("üîä “ö–∞–∑–∞“õ—à–∞", key=f"sound_kk_{term['kk']}"):
                    text_to_speech(term['kk'], 'kk')
        with cols[1]:
            if term.get('ru'):
                if st.button("üîä –†—É—Å—Å–∫–∏–π", key=f"sound_ru_{term['ru']}"):
                    text_to_speech(term['ru'], 'ru')
        with cols[2]:
            if term.get('en'):
                if st.button("üîä English", key=f"sound_en_{term['en']}"):
                    text_to_speech(term['en'], 'en')
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        tabs = st.tabs(["üìñ –ê–Ω—ã“õ—Ç–∞–º–∞", "üí¨ –ú—ã—Å–∞–ª", "üîó –ë–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä"])
        definition = term.get('definition', {})
        example = term.get('example', {})
        relations = term.get('relations', {})

        with tabs[0]:
            st.markdown(f"**KK:** {definition.get('kk', '-')}")
            st.markdown(f"**RU:** {definition.get('ru', '-')}")
            st.markdown(f"**EN:** {definition.get('en', '-')}")
        
        with tabs[1]:
            st.markdown(f"**KK:** {example.get('kk', '-')}")
            st.markdown(f"**RU:** {example.get('ru', '-')}")
            st.markdown(f"**EN:** {example.get('en', '-')}")
        
        with tabs[2]:
            cols = st.columns(2)
            with cols[0]:
                st.markdown("üîÅ **–°–∏–Ω–æ–Ω–∏–º–¥–µ—Ä:**\n" + "\n".join(f"- {s}" for s in relations.get('synonyms', [])))
                st.markdown("üîº **–ñ–∞–ª–ø—ã “±“ì—ã–º:**\n" + "\n" relations.get('general_concept', []))
            with cols[1]:
                st.markdown("üîΩ **–ê—Ä–Ω–∞–π—ã “±“ì—ã–º–¥–∞—Ä:**\n" + "\n".join(f"- {s}" for s in relations.get('specific_concepts', [])))
                st.markdown("üîó **–ê—Å—Å–æ—Ü–∏–∞—Ü–∏—è–ª–∞—Ä:**\n" + "\n".join(f"- {s}" for s in relations.get('associative', [])))
def text_to_speech(text, lang):
    """–¢–µ–∫—Å—Ç—Ç—ñ –¥—ã–±—ã—Å—Ç–∞—É “Ø—à—ñ–Ω JavaScript —Ñ—É–Ω–∫—Ü–∏—è—Å—ã"""
    js_code = f"""
    <script>
        function speak() {{
            const synth = window.speechSynthesis;
            const utterance = new SpeechSynthesisUtterance();
            utterance.text = "{text}";
            utterance.lang = "{'kk-KZ' if lang == 'kk' else lang + '-RU' if lang == 'ru' else 'en-US'}";
            synth.speak(utterance);
        }}
        speak();
    </script>
    """
    html(js_code, height=0)
def display_pagination(total_terms):
    total_pages = (total_terms + ITEMS_PER_PAGE - 1) // ITEMS_PER_PAGE
    prev_col, _, next_col = st.columns([1, 8, 1])
    
    with prev_col:
        if st.button("‚óÄÔ∏è –ê–ª–¥—ã“£“ì—ã", disabled=(st.session_state.current_page == 0)):
            st.session_state.current_page -= 1
            st.rerun()
    
    with next_col:
        if st.button("–ö–µ–ª–µ—Å—ñ ‚ñ∂Ô∏è", disabled=(st.session_state.current_page >= total_pages-1)):
            st.session_state.current_page += 1
            st.rerun()
    
    st.caption(f"–ë–µ—Ç {st.session_state.current_page + 1}/{total_pages}")

# ==================== –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
def main():
    st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫", layout="wide")
    st.title("üìò –ê–ö–¢ –∫—É—Ä—Å—ã: –≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫")
    
    terms_data, sha = load_github_data()
    if 'current_page' not in st.session_state:
        st.session_state.current_page = 0
    
    if not terms_data or not isinstance(terms_data, dict):
        st.error("‚ùå –î–µ—Ä–µ–∫—Ç–µ—Ä –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ –Ω–µ–º–µ—Å–µ “õ–∞—Ç–µ —Ñ–æ—Ä–º–∞—Ç")
        return
    
    all_terms = [term for lecture in terms_data.values() for term in lecture]
    
    with st.sidebar:
        uploaded_file = st.file_uploader("üì§ Excel —Ñ–∞–π–ª –∂“Ø–∫—Ç–µ—É", type=["xlsx"])
        if uploaded_file:
            new_terms = parse_excel(uploaded_file)
            if new_terms:
                st.success(f"‚úÖ {len(new_terms)} –∂–∞“£–∞ —Ç–µ—Ä–º–∏–Ω —Ç–∞–±—ã–ª–¥—ã!")
                lecture_options = list(terms_data.keys()) + ["+ –ñ–ê“¢–ê –¢–ê“ö–´–†–´–ü"]
                selected_lecture = st.selectbox("üìö –¢–∞“õ—ã—Ä—ã–ø —Ç–∞“£–¥–∞“£—ã–∑:", lecture_options, index=0)

                if selected_lecture == "+ –ñ–ê“¢–ê –¢–ê“ö–´–†–´–ü":
                    new_lecture_name = st.text_input("–ñ–∞“£–∞ —Ç–∞“õ—ã—Ä—ã–ø –∞—Ç–∞—É—ã:")
                    if new_lecture_name:
                        selected_lecture = new_lecture_name
                        terms_data[selected_lecture] = []  
                
                if selected_lecture not in terms_data:
                    terms_data[selected_lecture] = []

                if st.button("üíæ –°–∞“õ—Ç–∞—É"):
                     st.cache_data.clear()
                     terms_data, _ = load_github_data()
                     terms_data[selected_lecture].extend(new_terms)
                     if update_github(terms_data):
                        st.rerun()
        
        if st.button("üåç –ë–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä–¥—ã –∫”©—Ä—Å–µ—Ç—É"):
            html_content = "<div style='padding:20px; font-family:Arial;'><h3>üîó –°–µ–º–∞–Ω—Ç–∏–∫–∞–ª—ã“õ –±–∞–π–ª–∞–Ω—ã—Å—Ç–∞—Ä</h3>"
            for lecture in terms_data.values():
                for term in lecture:
                    try:
                        kk = term.get('kk', '–ê—Ç–∞—É—ã –∂–æ“õ')
                        relations = term.get('relations', {})
                        elements = []
                        if 'synonyms' in relations:
                            elements.extend(relations['synonyms'])
                        if 'specific' in relations:
                            elements.extend(relations['specific'])
                        html_content += f"<p><b>{kk}</b> ‚Üí {', '.join(elements)}</p>"
                    except:
                        continue
            html_content += "</div>"
            html(html_content, height=500, scrolling=True)

    view_mode = st.radio("üîç –ö”©—Ä—ñ–Ω—É —Ä–µ–∂–∏–º—ñ:", ["üìÇ –¢–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞", "üîé –ë–∞—Ä–ª—ã“õ —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä–¥–µ–Ω —ñ–∑–¥–µ—É"], horizontal=True)

    if view_mode == "üìÇ –¢–∞“õ—ã—Ä—ã–ø –±–æ–π—ã–Ω—à–∞":
        selected_lecture = st.selectbox("üìö –¢–∞“õ—ã—Ä—ã–ø—Ç—ã —Ç–∞“£–¥–∞“£—ã–∑:", list(terms_data.keys()), index=0, key="lecture_selector")
        st.subheader(f"üìñ –¢–∞“õ—ã—Ä—ã–ø: {selected_lecture}")
        
        initial_terms = sorted(
            terms_data[selected_lecture],
            key=lambda x: x.get('kk', '').lower() )
        letters = sorted({term['kk'][0].upper() for term in initial_terms if term.get('kk')})

        used_letters = [letter for letter in KAZ_ALPHABET 
                       if any(term.get('kk', '').upper().startswith(letter) 
                             for term in initial_terms)]
        
        selected_letter = st.session_state.get('selected_letter', '–ë–∞—Ä–ª—ã“ì—ã')
        
        with st.container():
            # –ö–Ω–æ–ø–∫–∞ "–í—Å–µ"
            if st.button("üåê –ë–∞—Ä–ª—ã“ì—ã", use_container_width=True):
                selected_letter = '–ë–∞—Ä–ª—ã“ì—ã'
                st.session_state.selected_letter = selected_letter
                st.session_state.current_page = 0
                st.rerun()
            BUTTONS_PER_ROW = 8
            for i in range(0, len(used_letters), BUTTONS_PER_ROW):
                row_letters = used_letters[i:i+BUTTONS_PER_ROW]
                
                empty_cols = (BUTTONS_PER_ROW - len(row_letters)) // 2
                columns = st.columns([1]*empty_cols + [2]*len(row_letters) + [1]*empty_cols)
                
                for idx, letter in enumerate(row_letters):
                    with columns[empty_cols + idx]:
                        if st.button(
                            letter,
                            key=f"btn_{letter}_{i}",
                            help=f"”ò—Ä—ñ–ø–ø–µ–Ω –±–∞—Å—Ç–∞–ª–∞—Ç—ã–Ω —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä: {letter}",
                            use_container_width=True
                        ):
                            selected_letter = letter
                            st.session_state.selected_letter = selected_letter
                            st.session_state.current_page = 0
                            st.rerun()

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤
        filtered_terms = [
            term for term in initial_terms
            if selected_letter == '–ë–∞—Ä–ª—ã“ì—ã' or 
            term.get('kk', '').upper().startswith(selected_letter)
        ]
    
        col1, col2 = st.columns([3, 2])
        with col1:
            sort_option = st.selectbox(
                "üîÉ –°“±—Ä—ã–ø—Ç–∞—É —Ç“Ø—Ä—ñ",
                options=[
                    "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–ê-–Ø)",
                    "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–Ø-–ê)"
                ],
                index=0
            )
        
        if sort_option == "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–ê-–Ø)":
            filtered_terms.sort(key=lambda x: x.get('kk', ''))
        elif sort_option == "–ê–ª—Ñ–∞–≤–∏—Ç –±–æ–π—ã–Ω—à–∞ (–Ø-–ê)":
            filtered_terms.sort(key=lambda x: x.get('kk', ''), reverse=True)
        elif sort_option == "–ú—ã—Å–∞–ª–¥–∞—Ä—ã –±–∞—Ä–ª–∞—Ä –∞–ª–¥—ã–º–µ–Ω":
            filtered_terms.sort(key=lambda x: len(x.get('example', {}).get('kk', '')), reverse=True)

        if st.session_state.get('prev_lecture') != selected_lecture or st.session_state.get('prev_letter') != selected_letter:
            st.session_state.current_page = 0
            st.session_state.prev_lecture = selected_lecture
            st.session_state.prev_letter = selected_letter
        
        start_idx = st.session_state.current_page * ITEMS_PER_PAGE
        paginated_terms = filtered_terms[start_idx : start_idx + ITEMS_PER_PAGE]
            
        st.write(f"üî¢ –ñ–∞–ª–ø—ã —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä: {len(filtered_terms)}")

        if paginated_terms:
            display_terms_in_columns(paginated_terms, start_idx)
            display_pagination(len(filtered_terms))
        else:
            st.warning("üì≠ –û—Å—ã –±–µ—Ç—Ç–µ —Ç–µ—Ä–º–∏–Ω–¥–µ—Ä –∂–æ“õ")

        if st.session_state.get('selected_term'):
            display_term_full(st.session_state.selected_term)
            if st.button("‚ùå –ñ–∞–±—É"):
                del st.session_state.selected_term
                st.rerun()
    else:
        search_query = st.text_input("üîç –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ —ñ–∑–¥–µ—É", help="–ö–µ–∑ –∫–µ–ª–≥–µ–Ω —Ç—ñ–ª–¥–µ —ñ–∑–¥–µ“£—ñ–∑")
        filtered_terms = [
            term for term in all_terms
            if search_query.lower() in str(term).lower()
        ] if search_query else all_terms
        
        if filtered_terms:
            st.subheader(f"üìö –¢–∞–±—ã–ª–¥—ã: {len(filtered_terms)} —Ç–µ—Ä–º–∏–Ω")
            for idx, term in enumerate(filtered_terms):
                display_term_compact(term, idx)
        else:
            st.info("üîç –ï—à—Ç–µ“£–µ —Ç–∞–±—ã–ª“ì–∞–Ω –∂–æ“õ. –Ü–∑–¥–µ—É —Å“±—Ä–∞–Ω—ã—Å—ã–Ω ”©–∑–≥–µ—Ä—Ç—ñ“£—ñ–∑.")

if __name__ == "__main__":
    main()
