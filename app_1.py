import streamlit as st
import json
import pandas as pd
import requests
import base64
from difflib import get_close_matches
from streamlit.components.v1 import html

# ==================== –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ====================
GITHUB_TOKEN = st.secrets["GITHUB_TOKEN"]
REPO_OWNER = st.secrets["REPO_OWNER"]
REPO_NAME = st.secrets["REPO_NAME"]
FILE_PATH = "data.json"

headers = {
    "Authorization": f"token {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

# ==================== –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
@st.cache_data
def load_json_from_github():
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
    res = requests.get(url, headers=headers)
    if res.status_code == 200:
        content = base64.b64decode(res.json()["content"]).decode("utf-8")
        sha = res.json()["sha"]
        return json.loads(content), sha
    else:
        st.error(f"‚ùå GitHub-—Ç–∞–Ω –¥–µ—Ä–µ–∫ –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ: {res.status_code}")
        return {}, None
# GitHub-“õ–∞ –∂–∞“£–∞ JSON –∂–∞–∑—É
def update_json_to_github(new_data, sha):
    url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{FILE_PATH}"
    updated_content = json.dumps(new_data, ensure_ascii=False, indent=2).encode("utf-8")
    b64_content = base64.b64encode(updated_content).decode("utf-8")

    data = {
        "message": "üîÑ –¢–µ—Ä–º–∏–Ω–¥–µ—Ä –∂–∞“£–∞—Ä—Ç—ã–ª–¥—ã",
        "content": b64_content,
        "sha": sha
    }
    response = requests.put(url, headers=headers, json=data)
    if response.status_code == 200 or response.status_code == 201:
        st.success("‚úÖ –¢–µ—Ä–º–∏–Ω–¥–µ—Ä GitHub-—Ç–∞ –∂–∞“£–∞—Ä—Ç—ã–ª–¥—ã!")
    else:
        st.error(f"‚ùå GitHub-“õ–∞ –∂–∞–∑—É “õ–∞—Ç–µ—Å—ñ: {response.text}")

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ “±“ì—ã–º–¥—ã“õ-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫", layout="wide")
st.title("üìò –ê–ö–¢ –∫—É—Ä—Å—ã: –≠–ª–µ–∫—Ç—Ä–æ–Ω–¥—ã“õ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è–ª—ã“õ —Å”©–∑–¥—ñ–∫")

terms, sha = load_json_from_github()

# Excel –∂“Ø–∫—Ç–µ—É
uploaded_file = st.sidebar.file_uploader("üì§ Excel —Ñ–∞–π–ª –∂“Ø–∫—Ç–µ—É (xlsx)", type=["xlsx"])
if uploaded_file:
    try:
        df = pd.read_excel(uploaded_file)
        new_terms = []
        for _, row in df.iterrows():
            term = {
                'kk': row.get('kk', ''),
                'ru': row.get('ru', ''),
                'en': row.get('en', ''),
                'definition': {
                    'kk': row.get('definition_kk', ''),
                    'ru': row.get('definition_ru', ''),
                    'en': row.get('definition_en', '')
                },
                'example': {
                    'kk': row.get('example_kk', ''),
                    'ru': row.get('example_ru', ''),
                    'en': row.get('example_en', '')
                },
                'relations': {
                    'synonyms': str(row.get('relations_synonyms', '')).split(',') if row.get('relations_synonyms') else [],
                    'general_concept': row.get('relations_general_concept', ''),
                    'specific_concepts': str(row.get('relations_specific_concepts', '')).split(',') if row.get('relations_specific_concepts') else [],
                    'associative': str(row.get('relations_associative', '')).split(',') if row.get('relations_associative') else []
                }
            }
            new_terms.append(term)

        lecture_name = st.sidebar.selectbox("üìö “ö–∞–π –¥”ô—Ä—ñ—Å–∫–µ “õ–æ—Å—ã–ª–∞–¥—ã?", list(terms.keys()))
        if st.sidebar.button("‚ûï –¢–µ—Ä–º–∏–Ω–¥–µ—Ä–¥—ñ “õ–æ—Å—É"):
            terms[lecture_name].extend(new_terms)
            with open("data.json", "w", encoding="utf-8") as f:
                json.dump(terms, f, ensure_ascii=False, indent=2)
            st.success(f"‚úÖ {len(new_terms)} –∂–∞“£–∞ —Ç–µ—Ä–º–∏–Ω “õ–æ—Å—ã–ª–¥—ã!")
            st.session_state['selected_term'] = None
            st.experimental_rerun()

    except Exception as e:
        st.error(f"‚ùå Excel –æ“õ—É “õ–∞—Ç–µ—Å—ñ: {e}")

def parse_excel(uploaded_file):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ Excel-—Ñ–∞–π–ª–∞ —Å —Ç–µ—Ä–º–∏–Ω–∞–º–∏"""
    try:
        df = pd.read_excel(uploaded_file)
        return [
            {
                'kk': row.get('kk', ''),
                'ru': row.get('ru', ''),
                'en': row.get('en', ''),
                'definition': {
                    'kk': row.get('definition_kk', ''),
                    'ru': row.get('definition_ru', ''),
                    'en': row.get('definition_en', '')
                },
                'example': {
                    'kk': row.get('example_kk', ''),
                    'ru': row.get('example_ru', ''),
                    'en': row.get('example_en', '')
                },
                'relations': {
                    'synonyms': [s.strip() for s in str(row.get('synonyms', '')).split(',')],
                    'general': [s.strip() for s in str(row.get('general_concept', '')).split(',')],
                    'specific': [s.strip() for s in str(row.get('specific_concepts', '')).split(',')],
                    'associative': [s.strip() for s in str(row.get('associative', '')).split(',')]
                }
            }
            for _, row in df.iterrows()
        ]
    
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel: {str(e)}")
        return []

# ==================== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ====================
def display_term_compact(term):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–µ—Ä–º–∏–Ω–∞ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ (—Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ)"""
    kk_title = term.get('kk', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
    if st.button(f"üîπ {kk_title}", key=f"compact_{kk_title}"):
        st.session_state.selected_term = term

def display_term_full(term):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ—Ä–º–∏–Ω–µ"""
    with st.expander(f"üìò {term.get('kk', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}", expanded=True):
        tabs = st.tabs(["üìñ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "üí¨ –ü—Ä–∏–º–µ—Ä", "üîó –°–≤—è–∑–∏"])
        
        definition = term.get('definition', {})
        example = term.get('example', {})
        relations = term.get('relations', {})

        with tabs[0]:
            st.markdown(f"**KK:** {definition.get('kk', '-')}")
            st.markdown(f"**RU:** {definition.get('ru', '-')}")
            st.markdown(f"**EN:** {definition.get('en', '-')}")
        
        with tabs[1]:
            st.markdown(f"**KK:** {example.get('kk', '-')}")
            st.markdown(f"**RU:** {example.get('ru', '-')}")
            st.markdown(f"**EN:** {example.get('en', '-')}")
        
        with tabs[2]:
            cols = st.columns(2)
            with cols[0]:
                st.markdown("üîÅ **–°–∏–Ω–æ–Ω–∏–º—ã:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('synonyms', [])
                ))
                st.markdown("üîº **–û–±—â–µ–µ –ø–æ–Ω—è—Ç–∏–µ:**\n" + relations.get('general', '-'))
            with cols[1]:
                st.markdown("üîΩ **–ß–∞—Å—Ç–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('specific', [])
                ))
                st.markdown("üîó **–ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏:**\n" + "\n".join(
                    f"- {s}" for s in relations.get('associative', [])
                ))
# ==================== –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
def main():
    st.set_page_config("–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å", layout="wide")
    st.title("üìö –¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –ê–ö–¢")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    terms_data, sha = load_github_data()
    all_terms = [term for lecture in terms_data.values() for term in lecture]
    
    # ==================== –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å ====================
    with st.sidebar:
        st.header("‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ Excel
        uploaded_file = st.file_uploader("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç—å Excel", type=["xlsx"])
        if uploaded_file:
            new_terms = parse_excel(uploaded_file)
            if new_terms:
                selected_lecture = st.selectbox("üìö –í—ã–±–µ—Ä–∏—Ç–µ –ª–µ–∫—Ü–∏—é", list(terms_data.keys()))
                if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ—Ä–º–∏–Ω—ã"):
                    terms_data[selected_lecture].extend(new_terms)
                    update_github(terms_data, sha)
                    st.rerun()
        
        # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –∫–∞—Ä—Ç–∞
        if st.button("üåç –ü–æ–∫–∞–∑–∞—Ç—å —Å–≤—è–∑–∏"):
            html_content = "<div style='padding:20px; font-family:Arial;'>"
            html_content += "<h3>üîó –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏</h3>"
            
            for lecture in terms_data.values():
                for term in lecture:
                    try:
                        kk = term.get('kk', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                        relations = term.get('relations', {})
                        elements = []
                        if 'synonyms' in relations:
                            elements.extend(relations['synonyms'])
                        if 'specific' in relations:
                            elements.extend(relations['specific'])
                        html_content += f"<p><b>{kk}</b> ‚Üí {', '.join(elements)}</p>"
                    except Exception as e:
                        continue
            
            html_content += "</div>"
            html(html_content, height=500, scrolling=True)

    # ==================== –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ====================
    # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å —Ä–µ–∂–∏–º–æ–≤
    view_mode = st.radio("üîç –†–µ–∂–∏–º –ø—Ä–æ—Å–º–æ—Ç—Ä–∞:", 
                        ["üìÇ –ü–æ —Ç–µ–º–∞–º", "üîé –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —Ç–µ—Ä–º–∏–Ω–∞–º"], 
                        horizontal=True)

    if view_mode == "üìÇ –ü–æ —Ç–µ–º–∞–º":
        selected_lecture = st.selectbox(
            "üìö –í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É:",
            list(terms_data.keys()),
            index=0,
            key="lecture_selector"
        )

        st.subheader(f"üìñ –¢–µ–º–∞: {selected_lecture}")
        st.write(f"üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Ä–º–∏–Ω–æ–≤ 1: {len(terms_data[selected_lecture])}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
        if 'selected_term' not in st.session_state:
            st.session_state.selected_term = None
            
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ç–µ—Ä–º–∏–Ω–æ–≤
        for term in terms_data[selected_lecture]:
            display_term_compact(term)
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞
        if st.session_state.selected_term:
            display_term_full(st.session_state.selected_term)
            if st.button("‚ùå –ó–∞–∫—Ä—ã—Ç—å"):
                st.session_state.selected_term = None
                st.rerun()

    else:
        # –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —Ç–µ—Ä–º–∏–Ω–∞–º
        search_query = st.text_input("üîç –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º —Ç–µ—Ä–º–∏–Ω–∞–º", help="–ò—â–∏—Ç–µ –Ω–∞ –ª—é–±–æ–º —è–∑—ã–∫–µ")
        filtered_terms = [
            term for term in all_terms
            if search_query.lower() in str(term).lower()
        ] if search_query else all_terms
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if filtered_terms:
            st.subheader(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ä–º–∏–Ω–æ–≤: {len(filtered_terms)}")
            for term in filtered_terms:
                display_term(term)
                st.divider()
        else:
            st.info("üîç –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")

if __name__ == "__main__":
    main()
